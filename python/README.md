##Goal

This generator generate the rules and training parts (gold) for the C++ implementation.

To generate the training parts (gold), you have to generate the rules somewhere as a file first.


##Argument List

```
gr_or_gp (required) -> type=int, -> Generate Rules -- 0, Generate Parts -- 1, Generate CONLL from Phrase Treebank -- 2.
--inputf (required) -> type=str, -> input file, can be the treebank file (in case 0 and 1) or conll file (in case 2).
--rulef (required in mode 1)-> type=str, -> the rule file generated by case 0.
```

An example usage of this can be:

Generate rule files
```
python Generator.py 0 --inputf /home/username/PTB/penn_tb_3.0_preprocessed/train.withtop > rules
```

Generate gold parts
```
python Generator.py 1 --inputf /home/username/PTB/penn_tb_3.0_preprocessed/train.withtop --rulef rules > parts
```

To generate CONLL format dependency trees (extract dependencies) from phrase structure treebank, simply use:
```
python Generator.py 2 --inputf /media/username/Data/PTB/penn_tb_3.0_preprocessed/train.withtop > train.conll
```

##How to train
Basically, you need the three files generated from the phrase-structured treebank here (i.e. rules, parts and train.conll)
to train a new system.

They are exactly the three files mentioned in the PADt command line
```
> ./padt --grammar rules --model model --annotations parts --conll train.conll --epochs 5 --simple_features
```

Besides that, you need train.conll to train a dependeny parser to generate Collins format dependencies.

For example, if you are using TurboParser (http://www.ark.cs.cmu.edu/TurboParser/) as your dependency parser, the training command line would be
```
./TurboParser --train \
--file_train=train.conll \
--file_model=parsing.model \
--prune_basic=true \
--model_type=standard \
--logtostderr
``` 

##NOTE
We assume phrase structure treebank files are one tree per line. All the phrase strcture trees are warpped with (TOP ...)

e.g.

(TOP (S (NP (NNP Ms.) (NNP Haag)) (VP (VBZ plays) (NP (NNP Elianti))) (. .)))

